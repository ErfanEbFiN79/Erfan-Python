{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+jjFvPdhiaVZHYCrjs4oR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErfanEbFiN79/Erfan-Python/blob/main/Python%20Erfan/Machine%20Learning/Start_01/Machine_Learning_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning: Supervised Learning\n"
      ],
      "metadata": {
        "id": "OzBdUUbhCzzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "aghI3aKnKroh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Motivation"
      ],
      "metadata": {
        "id": "zkaiWA7GC3ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Classification: where you output variable y can take on only one of a small handful of possible values instead of any number in an infinite range of numbers\n",
        "\n",
        "Some classification example:\n",
        "* Is this email spam? = $y$ > No/Yes\n",
        "* Is the transaction fraudulent? = $y$ > No/Yes\n",
        "* Is the tumor maligant? = $y$ > No/Yes\n",
        "\n",
        "> Note: $y$ can only be one of two values (it's called binary classification)\n",
        "\n",
        "> NOTE: Class = Category\n",
        "\n",
        "we often designate clauses as **NO** or **Yes** or sometimes equivalently **False** or **True** or very commonly using the numbers **0** or **1**\n",
        "\n",
        ">NOTE:\\\n",
        "0 =>**Negative class**\\\n",
        "1 => **Positive Class**\n",
        "\n",
        "We can't use linear regression, it's predicts not just values 0 and 1 but all number between 0 and 1 or even less than 0 or greater than 1,\n",
        "but here we want to predict categories,\n",
        "But HOW?\n",
        "1. Pick a threshold\n"
      ],
      "metadata": {
        "id": "s5FCSMiBC-n1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehMF0RPbC23G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "UCQ_qEgrw8un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> NOTE: It's the single most widely used classification algorithm in the world.\n",
        "\n",
        "Let's work with a example we whant to classifying whether a tumor is malignant at this example we have:\n",
        "* two lables (Yes/No)(1/0)\n",
        "* some result on 0 and some are on 1\n",
        "\n",
        "Horizontal axis is the tumor size and vertical axis takes on only values of 0 and 1 because it's a classification problem\\\n",
        "We know linear regression is not a good algorithm for this problem\n",
        "> What logistic regression doing?\\\n",
        "fit a curve that look like across all the points (it's like a S shape)\n",
        "\n",
        "! We want output between 0 and 1\n",
        "\n",
        "to build up to the logistic regression algorithm there's an important mathematical function I'd like to describe which is called the **sigmoid function** also call it **logistic function**\n",
        "> NOTE: the sigmoid function outputs values between 0 and 1\n",
        "\n",
        "If we use G and Z to denote this function:\n",
        "> Formula: $g(z) = \\frac{1}{1 + e^{-z}}$   0 < $g(z)$ < 1\n",
        "\n",
        "$e$ is a mathematical constant that takes on a value of about 2.7 and so $e^{-z}$ is that mathematical constant to the power of negative $Z$\n",
        "> NOTE: if $z$ were really big $e^{-z}$ is go to be a tiny tiny number\n",
        "\n",
        "> NOTE: if $z$ = 0 the $e^{-z}$ = $e^{0}$ which is equal to 1 so $g(z)$ = 0.5\n",
        "\n"
      ],
      "metadata": {
        "id": "Bs86LoRaxFqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use this to build up to the logistic regression algorithm, we're going to do this in two steps:\n",
        "1. first you need to remember linear regression function :\\\n",
        "$f_{W,b}(X) = W.X + b$\\\n",
        "we can store this value in a variable which I'm going to call $z$ ans this will turn out to be tha same $z$ as the one you saw on on previous we taked.\n",
        "2. Next step is to take this value of $z$ and pass it to the sigmoid function (logistic function)\n",
        "\n",
        "Now if we put eveything next to other:\n",
        "> Logistic regression model:\\\n",
        "$f_{W,b}(X) = g(W.X + b) = \\frac{1}{1 + e^{-(W.X+b)}}$\\\n",
        "!! $(W.X+b) = z$\n",
        "\n",
        "What it does is it inputs a feature or set a feature x and it outputs a number between 0 and 1."
      ],
      "metadata": {
        "id": "GdaiCtXWmLCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take look at how to interpret the output of logistic regression:\n",
        "\n",
        "> MEMORY: $f_{W,b}(X) = \\frac{1}{1 + e^{-(W.X+b)}}$\n",
        "\n",
        "> NOTE: the way you to think of logistice regressions output is thick of it as outputting the probability that the cost or label y will be equal to 1 given a certain input X\n",
        "\n",
        "Let's continue with last example about tumor size:\\\n",
        "Example:\\\n",
        "$x$ is \"tumor size\"\\\n",
        "$y$ is 0 (not malignant) or 1 (malignant)\\\n",
        "\n",
        "if a patient come in and she\\he has a tumor of a certain size x:\\\n",
        "$f_{W,b}(X) = 0.7$\\\n",
        "that means is that the model is preficting or the model thinks there is a 70% chance that the true lable y will be equal to 1 for this patient\n",
        "\n",
        "so if y has a 70% chance of being one what is the chance that it is 0?\\\n",
        "> EXPLAIN: $P(y = 0) + P(y=1) = 1$\n",
        "\n",
        "so for our example the chance of it being zero has got to be 0.3 or 30% chance\n",
        "> $f_{W,b}(X) = P(y = 1|X;W,b)$\\\n",
        "; in here means W and b are parameters that affect this computation of what is the probability of Y being equal to 1 given the input feature X"
      ],
      "metadata": {
        "id": "8Ny_Q-KMrVuh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Apl2vmpNtexd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}